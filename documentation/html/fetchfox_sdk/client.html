<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.0">
<title>fetchfox_sdk.client API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>fetchfox_sdk.client</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="fetchfox_sdk.client.FetchFox"><code class="flex name class">
<span>class <span class="ident">FetchFox</span></span>
<span>(</span><span>api_key: Optional[str] = None, host: str = 'https://fetchfox.ai', quiet=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the FetchFox SDK.</p>
<p>You may also provide an API key in the environment variable <code>FETCHFOX_API_KEY</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>api_key</code></strong></dt>
<dd>Your FetchFox API key.
Overrides the environment variable.</dd>
<dt><strong><code>host</code></strong></dt>
<dd>API host URL (defaults to production)</dd>
<dt><strong><code>quiet</code></strong></dt>
<dd>set to True to suppress printing</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FetchFox:
    def __init__(self,
            api_key: Optional[str] = None, host: str = &#34;https://fetchfox.ai&#34;,
            quiet=False):
        &#34;&#34;&#34;Initialize the FetchFox SDK.

        You may also provide an API key in the environment variable `FETCHFOX_API_KEY`.

        Args:
            api_key: Your FetchFox API key.  Overrides the environment variable.
            host: API host URL (defaults to production)
            quiet: set to True to suppress printing
        &#34;&#34;&#34;
        self.base_url = urljoin(host, _API_PREFIX)

        self.api_key = api_key
        if self.api_key is None:
            self.api_key = os.environ.get(&#34;FETCHFOX_API_KEY&#34;)

        if not self.api_key:
            raise ValueError(
                &#34;API key must be provided either as argument or &#34;
                &#34;in FETCHFOX_API_KEY environment variable&#34;)

        self.headers = {
            &#39;Content-Type&#39;: &#39;application/json&#39;,
            &#39;Authorization&#39;: f&#39;Bearer: {self.api_key}&#39;
        }

        self.quiet = quiet
        self._executor = ThreadPoolExecutor(max_workers=1)
        # TODO: this needs to be changed to support concurrent job polling,
        # but I am setting it to 1 right now as a sanity-check


    def _request(self, method: str, path: str, json_data: Optional[dict] = None,
                    params: Optional[dict] = None) -&gt; dict:
        &#34;&#34;&#34;Make an API request.

        Args:
            method: HTTP method
            path: API path
            json_data: Optional JSON body
            params: Optional query string parameters
        &#34;&#34;&#34;
        url = urljoin(self.base_url, path)

        response = requests.request(
            method,
            url,
            headers=self.headers,
            json=json_data,
            params=params,
            timeout=(30,30)
        )

        response.raise_for_status()
        body = response.json()

        logger.debug(
            f&#34;Response from %s %s:\n%s  at %s&#34;,
            method, path, pformat(body), datetime.now())
        return body

    def _nqprint(self, *args, **kwargs):
        if not self.quiet:
            print(*args, **kwargs)

    def _workflow(self, url_or_urls: Union[str, List[str]] = None) -&gt; &#34;Workflow&#34;:
        &#34;&#34;&#34;Create a new workflow using this SDK instance.

        Examples of how to use a workflow:

        ```
        city_pages = fox \
            .workflow(&#34;https://locations.traderjoes.com/pa/&#34;) \
            .extract(
                item_template = {
                    &#34;url&#34;: &#34;Find me all the URLs for the city directories&#34;
                }
            )
        ```

        A workflow is kind of like a Django QuerySet.  It will not be executed
        until you attempt to use the results.

        ```
        list_of_city_pages = list(city_pages)
        # This would run the workflow and give you a list of items like:
            {&#39;url&#39;: &#39;https://....&#39;}
        ```

        You could export those results to a file:
        ```
        city_pages.export(&#34;city_urls.jsonl&#34;)
        city_pages.export(&#34;city_urls.csv&#34;)
        ```

        And then you could create a new workflow (or two) that use those results:

        ```
        store_info = city_pages.extract(
            item_template = {
                &#34;store_address&#34;: &#34;find me the address of the store&#34;,
                &#34;store_number&#34;: &#34;Find me the number of the store (it&#39;s in parentheses)&#34;,
                &#34;store_phone&#34;: &#34;Find me the phone number of the store&#34;
                }
        )

        store_urls = city_pages.extract(
            item_template = {
                &#34;url&#34;: &#34;Find me the URLs of Store detail pages.&#34;
            }
        )
        ```

        In the above snippets, the `city_pages` workflow was only ever executed
        once.

        Optionally, a URL and/or params may be passed here to initialize
        the workflow with them.

        Workflow parameters are given in a dictionary.  E.g. if your workflow
        has a `{{state_name}}` parameter, you might pass:

            { &#39;state_name&#39;: &#39;Alaska&#39; }

        or perhaps

            { &#39;state_name&#39;: [&#39;Alaska&#39;, &#39;Hawaii&#39;] }

        if you wish to run the workflow for both states and collect the results.

        Args:
            url: URL to start from
            params: Workflow parameters.
        &#34;&#34;&#34;
        w = Workflow(self)
        if url_or_urls:
            w = w.init(url_or_urls)
        # if params:
        #     w = w.configure_params(params)

        return w

    def workflow_from_json(self, json_workflow) -&gt; &#34;Workflow&#34;:
        &#34;&#34;&#34;Given a JSON string, such as you can generate in the wizard at
        https://fetchfox.ai, create a workflow from it.

        Once created, it can be used like a regular workflow.

        Args:
            json_workflow: This must be a valid JSON string that represents a Fetchfox Workflow.  You should not usually try to write these manually, but simply copy-paste from the web interface.
        &#34;&#34;&#34;
        return self._workflow_from_dict(json.loads(json_workflow))

    def _workflow_from_dict(self, workflow_dict):
        w = Workflow(self)
        w._workflow = workflow_dict
        return w

    def workflow_by_id(self, workflow_id) -&gt; &#34;Workflow&#34;:
        &#34;&#34;&#34;Use a public workflow ID

        Something like fox.workflow_by_id(ID).configure_params({state:&#34;AK&#34;}).export(&#34;blah.csv&#34;)

        &#34;&#34;&#34;
        workflow_json = self._get_workflow(workflow_id)
        return self.workflow_from_json(workflow_json)

    def _register_workflow(self, workflow: Workflow) -&gt; str:
        &#34;&#34;&#34;Create a new workflow.

        Args:
            workflow: Workflow object

        Returns:
            Workflow ID
        &#34;&#34;&#34;
        response = self._request(&#39;POST&#39;, &#39;workflows&#39;, workflow.to_dict())

        # NOTE: If we need to return anything else here, we should keep this
        # default behavior, but add an optional kwarg so &#34;full_response=True&#34;
        # can be supplied, and then we return everything
        return response[&#39;id&#39;]

    def _get_workflows(self) -&gt; list:
        &#34;&#34;&#34;Get workflows

        Returns:
            List of workflows
        &#34;&#34;&#34;
        response = self._request(&#34;GET&#34;, &#34;workflows&#34;)

        # NOTE: Should we return Workflow objects intead?
        return response[&#39;results&#39;]

    def _get_workflow(self, id) -&gt; dict:
        &#34;&#34;&#34;Get a registered workflow by ID.&#34;&#34;&#34;
        response = self._request(&#34;GET&#34;, f&#34;workflow/{id}&#34;)
        return response

    def _run_workflow(self, workflow_id: Optional[str] = None,
                    workflow: Optional[Workflow] = None,
                    params: Optional[dict] = None) -&gt; str:
        &#34;&#34;&#34;Run a workflow. Either provide the ID of a registered workflow,
        or provide a workflow object (which will be registered
        automatically, for convenience).

        You can browse https://fetchfox.ai to find publicly available workflows
        authored by others.  Copy the workflow ID and use it here.  Often,
        in this case, you will also want to provide parameters.

        Args:
            workflow_id: ID of an existing workflow to run
            workflow: A Workflow object to register and run
            params: Optional parameters for the workflow

        Returns:
            Job ID

        Raises:
            ValueError: If neither workflow_id nor workflow is provided
        &#34;&#34;&#34;
        if workflow_id is None and workflow is None:
            raise ValueError(
                &#34;Either workflow_id or workflow must be provided&#34;)

        if workflow_id is not None and workflow is not None:
            raise ValueError(
                &#34;Provide only a workflow or a workflow_id, not both.&#34;)

        if workflow is not None and not isinstance(workflow, Workflow):
            raise ValueError(
                &#34;The workflow argument must be a fetchfox_sdk.Workflow&#34;)
        if workflow_id and not isinstance(workflow_id, str):
            raise ValueError(
                &#34;The workflow_id argument must be a string &#34;
                &#34;representing a registered workflow&#39;s ID&#34;)

        if params is not None:
            raise NotImplementedError(&#34;Cannot pass params to workflows yet&#34;)
            # TODO:
            #   It sounds like these might be passed in the const/init step?
            #   Or, maybe they need to go in as a dictionary on the side?
            # TODO:
            #   https://docs.google.com/document/d/17ieru_HfU3jXBilcZqL1Ksf27rsVPvOIQ8uxmHi2aeE/edit?disco=AAABdjyFjgw
            #   allow list-expansion here like above, pretty cool

        if workflow_id is None:
            workflow_id = self._register_workflow(workflow) # type: ignore
            logger.info(&#34;Registered new workflow with id: %s&#34;, workflow_id)

        #response = self._request(&#39;POST&#39;, f&#39;workflows/{workflow_id}/run&#39;, params or {})
        response = self._request(&#39;POST&#39;, f&#39;workflows/{workflow_id}/run&#39;)

        # NOTE: If we need to return anything else here, we should keep this
        # default behavior, but add an optional kwarg so &#34;full_response=True&#34;
        # can be supplied, and then we return everything
        return response[&#39;jobId&#39;]

    def _get_job_status(self, job_id: str) -&gt; dict:
        &#34;&#34;&#34;Get the status and results of a job.  Returns partial results before
        eventually returning the full results.

        When job_status[&#39;done&#39;] == True, the full results are present in
        response[&#39;results&#39;][&#39;items&#39;].

        If you want to manage your own polling, you can use this instead of
        await_job_completion()

        NOTE: Jobs are not created immediately after you call run_workflow().
        The status will not be available until the job is scheduled, so this
        will 404 initially.
        &#34;&#34;&#34;
        return self._request(&#39;GET&#39;, f&#39;jobs/{job_id}&#39;)

    def _poll_status_once(self, job_id):
        &#34;&#34;&#34;Poll until we get one status response.  This may be more than one poll,
        if it is the first one, since the job will 404 for a while before
        it is scheduled.&#34;&#34;&#34;
        MAX_WAIT_FOR_JOB_ALIVE_MINUTES = 5 #TODO: reasonable?
        started_waiting_for_job_dt = None
        while True:
            try:
                status = self._get_job_status(job_id)
                self._nqprint(&#34;.&#34;, end=&#34;&#34;)
                sys.stdout.flush()

                #TODO print partial status?

                return status
            except requests.exceptions.HTTPError as e:
                if e.response.status_code in [404, 500]:
                    self._nqprint(&#34;x&#34;, end=&#34;&#34;)
                    sys.stdout.flush()
                    logger.info(&#34;Waiting for job %s to be scheduled.&#34;, job_id)

                    if started_waiting_for_job_dt is None:
                        started_waiting_for_job_dt = datetime.now()
                    else:
                        waited = datetime.now() - started_waiting_for_job_dt
                        if waited &gt; timedelta(minutes=MAX_WAIT_FOR_JOB_ALIVE_MINUTES):
                            raise RuntimeError(
                                f&#34;Job {job_id} is taking unusually long to schedule.&#34;)

                else:
                    raise

    def _cleanup_job_result_item(self, item):
        filtered_item = {
            k: v
            for k, v
            in item.items()
            if not k.startswith(&#39;_&#39;)
        }

        # TODO: What should we be doing with `_url`?
        # # Keep _url if we have no other keys
        # if not filtered_item and &#39;_url&#39; in item:
        filtered_item[&#39;_url&#39;] = item[&#39;_url&#39;]
        return filtered_item

    def _job_result_items_gen(self, job_id):
        &#34;&#34;&#34;Yield new result items as they arrive.&#34;&#34;&#34;
        self._nqprint(f&#34;Streaming results from: [{job_id}]: &#34;)

        seen_ids = set() # We need to track which have been yielded already

        MAX_WAIT_FOR_CHANGE_MINUTES = 5
        # Job will be assumed done/stalled after this much time passes without
        # a new result coming in.
        first_response_dt = None
        results_changed_dt = None

        while True:
            response = self._poll_status_once(job_id)
            # The above will block until we get one successful response
            if not first_response_dt:
                first_response_dt = datetime.now()

            # We are considering only the result_items here, not partials
            if &#39;items&#39; not in response[&#39;results&#39;]:
                waited_dur = datetime.now() - first_response_dt
                if waited_dur &gt; timedelta(minutes=MAX_WAIT_FOR_CHANGE_MINUTES):
                    raise RuntimeError(
                        &#34;This job is taking too long - please retry.&#34;)
                continue

            for job_result_item in response[&#39;results&#39;][&#39;items&#39;]:
                jri_id = job_result_item[&#39;_meta&#39;][&#39;id&#39;]
                if jri_id not in seen_ids:
                    # We have a new result_item
                    results_changed_dt = datetime.now()
                    seen_ids.add(jri_id)
                    self._nqprint(&#34;&#34;)
                    yield self._cleanup_job_result_item(job_result_item)

            if results_changed_dt:
                waited_dur2 = results_changed_dt - datetime.now()
                if waited_dur2 &gt; timedelta(minutes=MAX_WAIT_FOR_CHANGE_MINUTES):
                    # It has been too long since we&#39;ve seen a new result, so
                    # we will assume the job is stalled on the server
                    break

            if response.get(&#34;done&#34;) == True:
                break

            time.sleep(1)

    def extract(self, url_or_urls, *args, **kwargs):
        &#34;&#34;&#34;Extract items from a given URL, given an item template.

        An item template is a dictionary where the keys are the desired
        output fieldnames and the values are the instructions for extraction of
        that field.

        Example item templates:
        {
            &#34;magnitude&#34;: &#34;What is the magnitude of this earthquake?&#34;,
            &#34;location&#34;: &#34;What is the location of this earthquake?&#34;,
            &#34;time&#34;: &#34;What is the time of this earthquake?&#34;
        }

        {
            &#34;url&#34;: &#34;Find me all the links to the product detail pages.&#34;
        }

        To follow pagination, provide max_pages &gt; 1.

        Args:
            item_template: the item template described above
            mode: &#39;single&#39;|&#39;multiple&#39;|&#39;auto&#39; - defaults to &#39;auto&#39;.  Set this to &#39;single&#39; if each URL has only a single item.  Set this to &#39;multiple&#39; if each URL should yield multiple items
            max_pages: enable pagination from the given URL.  Defaults to one page only.
            limit: limit the number of items yielded by this step
        &#34;&#34;&#34;
        return self._workflow(url_or_urls).extract(*args, **kwargs)

    def init(self, url_or_urls, *args, **kwargs):
        &#34;&#34;&#34;Initialize the workflow with one or more URLs.

        Args:
            url: Can be a single URL as a string, or a list of URLs.
        &#34;&#34;&#34;
        return self._workflow(url_or_urls)

    def filter(*args, **kwargs):
        raise RuntimeError(&#34;Filter cannot be the first step.&#34;)


    def unique(*args, **kwargs):
        raise RuntimeError(&#34;Unique cannot be the first step.&#34;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="fetchfox_sdk.client.FetchFox.extract"><code class="name flex">
<span>def <span class="ident">extract</span></span>(<span>self, url_or_urls, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Extract items from a given URL, given an item template.</p>
<p>An item template is a dictionary where the keys are the desired
output fieldnames and the values are the instructions for extraction of
that field.</p>
<p>Example item templates:
{
"magnitude": "What is the magnitude of this earthquake?",
"location": "What is the location of this earthquake?",
"time": "What is the time of this earthquake?"
}</p>
<p>{
"url": "Find me all the links to the product detail pages."
}</p>
<p>To follow pagination, provide max_pages &gt; 1.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>item_template</code></strong></dt>
<dd>the item template described above</dd>
<dt><strong><code>mode</code></strong></dt>
<dd>'single'|'multiple'|'auto' - defaults to 'auto'.
Set this to 'single' if each URL has only a single item.
Set this to 'multiple' if each URL should yield multiple items</dd>
<dt><strong><code>max_pages</code></strong></dt>
<dd>enable pagination from the given URL.
Defaults to one page only.</dd>
<dt><strong><code>limit</code></strong></dt>
<dd>limit the number of items yielded by this step</dd>
</dl></div>
</dd>
<dt id="fetchfox_sdk.client.FetchFox.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fetchfox_sdk.client.FetchFox.init"><code class="name flex">
<span>def <span class="ident">init</span></span>(<span>self, url_or_urls, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the workflow with one or more URLs.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>url</code></strong></dt>
<dd>Can be a single URL as a string, or a list of URLs.</dd>
</dl></div>
</dd>
<dt id="fetchfox_sdk.client.FetchFox.unique"><code class="name flex">
<span>def <span class="ident">unique</span></span>(<span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fetchfox_sdk.client.FetchFox.workflow_by_id"><code class="name flex">
<span>def <span class="ident">workflow_by_id</span></span>(<span>self, workflow_id) ‑> <a title="fetchfox_sdk.workflow.Workflow" href="workflow.html#fetchfox_sdk.workflow.Workflow">Workflow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Use a public workflow ID</p>
<p>Something like fox.workflow_by_id(ID).configure_params({state:"AK"}).export("blah.csv")</p></div>
</dd>
<dt id="fetchfox_sdk.client.FetchFox.workflow_from_json"><code class="name flex">
<span>def <span class="ident">workflow_from_json</span></span>(<span>self, json_workflow) ‑> <a title="fetchfox_sdk.workflow.Workflow" href="workflow.html#fetchfox_sdk.workflow.Workflow">Workflow</a></span>
</code></dt>
<dd>
<div class="desc"><p>Given a JSON string, such as you can generate in the wizard at
<a href="https://fetchfox.ai,">https://fetchfox.ai,</a> create a workflow from it.</p>
<p>Once created, it can be used like a regular workflow.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>json_workflow</code></strong></dt>
<dd>This must be a valid JSON string that represents a Fetchfox Workflow.
You should not usually try to write these manually, but simply copy-paste from the web interface.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="fetchfox_sdk" href="index.html">fetchfox_sdk</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="fetchfox_sdk.client.FetchFox" href="#fetchfox_sdk.client.FetchFox">FetchFox</a></code></h4>
<ul class="two-column">
<li><code><a title="fetchfox_sdk.client.FetchFox.extract" href="#fetchfox_sdk.client.FetchFox.extract">extract</a></code></li>
<li><code><a title="fetchfox_sdk.client.FetchFox.filter" href="#fetchfox_sdk.client.FetchFox.filter">filter</a></code></li>
<li><code><a title="fetchfox_sdk.client.FetchFox.init" href="#fetchfox_sdk.client.FetchFox.init">init</a></code></li>
<li><code><a title="fetchfox_sdk.client.FetchFox.unique" href="#fetchfox_sdk.client.FetchFox.unique">unique</a></code></li>
<li><code><a title="fetchfox_sdk.client.FetchFox.workflow_by_id" href="#fetchfox_sdk.client.FetchFox.workflow_by_id">workflow_by_id</a></code></li>
<li><code><a title="fetchfox_sdk.client.FetchFox.workflow_from_json" href="#fetchfox_sdk.client.FetchFox.workflow_from_json">workflow_from_json</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.0</a>.</p>
</footer>
</body>
</html>
